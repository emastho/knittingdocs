---
title: React SSR compression
description: SSR + Brotli compression on workers -- testing where compression should live.
hero:
  title: 'SSR + compression'
sidebar:
  order: 2

---

import { Tabs, TabItem } from '@astrojs/starlight/components';
import { Code } from '@astrojs/starlight/components';
import { getCode } from '../../../../../lib/code-snippets';
import DontDoubleParseTip from '../../../../../components/tips/DontDoubleParseTip.astro';
import LibraryInstallTabs from '../../../../../components/LibraryInstallTabs.astro';
import RuntimeRunTabs from '../../../../../components/RuntimeRunTabs.astro';

export const bench = getCode("data_transforms/react_ssr_compress/bench_react_ssr_compress.ts");
export const component = getCode("data_transforms/react_ssr_compress/render_user_card_compressed.tsx");
export const utils = getCode("data_transforms/react_ssr_compress/utils.ts");

Takes the React SSR example one step further: after rendering HTML, compress it with Brotli. This tests whether it's better to compress on the worker (render + compress in one shot) or on the host (render on worker, compress on main thread). Spoiler: doing both on the worker usually wins because you avoid sending uncompressed HTML back across the thread boundary.

## How it works

The host generates JSON payload strings. Both paths render the same user card component, then Brotli-compress the HTML output. The benchmark compares compressed byte totals for parity, then measures throughput.

- `bench_react_ssr_compress.ts` -- the benchmark
- `render_user_card_compressed.tsx` -- the SSR + compression task
- `utils.ts` -- shared payload and compression helpers

## Install

:::info
<LibraryInstallTabs
  jsrPackages={["@vixeny/knitting"]}
  npmPackages={["react", "react-dom", "mitata"]}
  denoUseNpmInterop={true}
/>
:::

Compression uses built-in `node:zlib` -- no extra packages.

## Benchmark

:::info
<RuntimeRunTabs
  bunCommand="bun src/bench_react_ssr_compress.ts"
  denoCommand="deno run -A src/bench_react_ssr_compress.ts"
/>
:::

Expected output:

```
byte parity check: host=42,380  worker=42,380  OK match

benchmark        avg (ns)    min ... max (ns)
host              45,600     41,200 ... 58,300
knitting          24,100     21,800 ... 32,400
```

Brotli is significantly more expensive than `renderToString` alone, so the worker advantage is more pronounced here than in the plain SSR example.

<DontDoubleParseTip />

## Code

<Tabs>
  <TabItem label="render_user_card_compressed.tsx">
    <Code code={component} lang="tsx" title={"render_user_card_compressed.tsx"} />
  </TabItem>
  <TabItem label="bench_react_ssr_compress.ts">
    <Code code={bench} lang="ts" title={"bench_react_ssr_compress.ts"} />
  </TabItem>
    <TabItem label="utils.ts">
    <Code code={utils} lang="ts" title={"utils.ts"} />
  </TabItem>
</Tabs>

## Compression placement matters

Where you compress affects both throughput and data transfer. If you compress on the worker, you send a small compressed buffer back to the host. If you compress on the host, you first transfer the full uncompressed HTML string across the thread boundary, then compress it. For response compression in a real server, doing render + compress on the worker is almost always the right call.