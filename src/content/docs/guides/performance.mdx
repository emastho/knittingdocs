---
title: Performance
description: Tips about performance and good practices.
sidebar:
  order: 6
---

import { Badge } from '@astrojs/starlight/components';

## Quick legend

Bear in mind that even <Badge text="Slow" variant="danger" /> here can still be **2-4x faster** than `postMessage` (depending on payload and workload).

- <Badge text="Best" variant="note" />: near "header-only" cost, best path
- <Badge text="Fast" variant="success" />: still very cheap per call
- <Badge text="Good" variant="tip" />: fine for real workloads
- <Badge text="Fair" variant="caution" />: watch frequency
- <Badge text="Slow" variant="danger" />: avoid in hot loops, consider alternatives

### Rating thresholds (easy to tweak later)

These tiers are intentionally simple. If you re-run benchmarks on a new CPU/runtime, edit these numbers and re-label rows as needed.

**For a single call (1 value):**
- Best: < 1 us
- Fast: < 2 us
- Good: < 4 us
- Fair: < 9 us
- Slow: > 9 us

**For a batch (100 values):**
- Best: < 50 us
- Fast: < 100 us
- Good: < 200 us
- Fair: < 450 us
- Slow: > 450 us

---

## Benchmark environment

- clk: ~3.86 GHz
- cpu: Apple M3 Ultra
- runtime: node 24.12.0 (arm64-darwin)


---

## Mental model (what makes things fast)

**1) Header-only / "no payload"**
Values fit into the call header: tiny encode/decode cost.

**2) Static payload**
Reuses part of the Header plus a small buffer, only for small playloads.

**3) Dynamic payload (allocator path)**
Needs allocation, copying, and bookkeeping. Still fast, but you'll feel it in hot loops.



---

## Single call categories (1 value)

<table>
  <thead>
    <tr>
      <th>Case</th>
      <th>Batch</th>
      <th>Tier</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Primitives: <code>boolean</code>, <code>undefined</code>, <code>null</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Numbers: <code>number</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Time/IDs: <code>Date</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Strings: small <code>string</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Symbols: <code>Symbol.for</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Fast" variant="success" /></td>
    </tr>
    <tr>
      <td>BigInt: small <code>bigint</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>BigInt: large <code>bigint</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Fast" variant="success" /></td>
    </tr>
    <tr>
      <td>Binary: Typed Arrays</td>
      <td><code>(1)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Views: <code>DataView</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Good" variant="tip" /></td>
    </tr>
    <tr>
      <td>Structured: <code>JSON object</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Good" variant="tip" /></td>
    </tr>
    <tr>
      <td>Structured: <code>JSON array</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Good" variant="tip" /></td>
    </tr>
    <tr>
      <td>Errors: <code>Error</code></td>
      <td><code>(1)</code></td>
      <td><Badge text="Slow" variant="danger" /></td>
    </tr>
  </tbody>
</table>

---

## Batch categories (100 values)

Batching amortizes overhead or if you are doing repeated calls.

<table>
  <thead>
    <tr>
      <th>Case</th>
      <th>Batch</th>
      <th>Tier</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Primitives: <code>boolean</code>, <code>undefined</code>, <code>null</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Numbers: <code>number</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Strings: small <code>string</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>BigInt: small <code>bigint</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>BigInt: large <code>bigint</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Fast" variant="success" /></td>
    </tr>
    <tr>
      <td>Binary: Typed Arrays </td>
      <td><code>(100)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Structured: <code>JSON object</code>, <code>JSON array</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Good" variant="tip" /></td>
    </tr>
    <tr>
      <td>Errors: <code>Error</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Slow" variant="danger" /></td>
    </tr>
    <tr>
      <td>Time/IDs: <code>Date</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
    <tr>
      <td>Symbols: <code>Symbol.for</code></td>
      <td><code>(100)</code></td>
      <td><Badge text="Best" variant="note" /></td>
    </tr>
  </tbody>
</table>

---

## Configuration effects on performance

### Thread count

More threads means more lanes for the balancer to distribute work across, but
each thread has a fixed memory cost (payload buffers, shared lock regions,
abort signal pool). Returns diminish past the number of physical cores. For
compute-only workloads, `threads: os.availableParallelism() - 1` is a
reasonable starting point.

### Inliner

The inliner skips encode/decode entirely, so header-only payloads on the
inline lane are effectively free. For tiny math tasks, adding
`inliner: { position: "last", batchSize: 64 }` can improve throughput
noticeably. See [Inliner guide](/guides/inliner).

### Permissions

Enabling `permission: "strict"` adds startup cost per worker (flag generation,
lock file resolution) but has no measurable per-call overhead once workers are
running. The cost is one-time and small.

### Payload sizing

`payloadInitialBytes` and `payloadMaxBytes` control the shared buffer each
worker allocates. Larger initial buffers avoid runtime growth at the cost of
upfront memory. If your payloads are consistently small (primitives, short
strings), the default 4 MiB initial / 64 MiB max is more than enough.

### Batching

Batching many calls amortizes header and dispatch overhead. Even types rated
<Badge text="Slow" variant="danger" /> in the single-call table become
acceptable when batched. If you're calling the same task in a loop, fire all
calls concurrently with `Promise.all` rather than awaiting each one
sequentially.